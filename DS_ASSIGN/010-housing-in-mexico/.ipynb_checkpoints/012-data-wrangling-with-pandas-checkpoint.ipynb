{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3cc495d",
   "metadata": {},
   "source": [
    "<font size=\"+3\"><strong>Preparing Mexico Data</strong></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5229f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15c7165",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa5df7",
   "metadata": {},
   "source": [
    "The first part of any data science project is preparing your data, which means making sure its in the right place and format for you to conduct your analysis. The first step of any data preparation is importing your raw data and cleaning it. \n",
    "\n",
    "If you look in the `small-data` directory on your machine, you'll see that the data for this project comes in three CSV files: `mexico-real-estate-1.csv`, `mexico-real-estate-2.csv`, and `mexico-real-estate-3.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0e5719",
   "metadata": {},
   "source": [
    "**Task 1.2.1:** Read these three files into three separate DataFrames named `df1`, `df2`, and `df3`, respectively.\n",
    "\n",
    "- **What's a DataFrame?**\n",
    "- **What's a CSV file?**\n",
    "- **Read a CSV file into a DataFrame using pandas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data/mexico-real-estate-1.csv\")\n",
    "df2 = pd.read_csv(\"data/mexico-real-estate-2.csv\")\n",
    "df3 = pd.read_csv(\"data/mexico-real-estate-3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9a7423",
   "metadata": {},
   "source": [
    "## Clean `df1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc04978",
   "metadata": {},
   "source": [
    "Now that you have your three DataFrames, it's time to inspect them to see if they need any cleaning. Let's look at them one-by-one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7b8e1a",
   "metadata": {},
   "source": [
    "**Task 1.2.2:** Inspect `df1` by looking at its [`shape`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html) attribute. Then use the [`info`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.htm) method to see the data types and number of missing values for each column. Finally, use the [`head`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html) method to determine to look at the first five rows of your dataset.\n",
    "\n",
    "- **Inspect a DataFrame using the `shape`, `info`, and `head` in pandas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c584110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape\n",
    "df1.info()\n",
    "df1.head()\n",
    "df1.head(2)\n",
    "df1.head(5)\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843da3a9",
   "metadata": {},
   "source": [
    "It looks like there are a couple of problems in this DataFrame that you need to solve. First, there are many rows with `NaN` values in the `\"lat\"` and `\"lon\"` columns. Second, the data type for the `\"price_usd\"` column is `object` when it should be `float`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cae8a33",
   "metadata": {},
   "source": [
    "**Task 1.2.3:** Clean `df1` by dropping rows with `NaN` values. Then remove the `\"$\"` and `\",\"` characters from `\"price_usd\"` and recast the values in the column as floats.\n",
    "\n",
    "- **What's a data type?**\n",
    "- **Drop rows with missing values from a DataFrame using pandas.**\n",
    "- **Replace string characters in a column using pandas.**\n",
    "- **Recast a column as a different data type in pandas.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75592c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'Nan' values\n",
    "df1.dropna(inplace=True)\n",
    "\n",
    "df1[\"price_usd\"].head()\n",
    "\n",
    "#Transform price from object to float\n",
    "df1[\"price_usd\"] = (\n",
    "    df1[\"price_usd\"]\n",
    "    .str.replace(\"$\", \"\", regex=False)\n",
    "    .str.replace(\",\", \"\")\n",
    "    .astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4987b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77023391",
   "metadata": {},
   "source": [
    "## Clean `df2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d171112",
   "metadata": {},
   "source": [
    "Now it's time to tackle `df2`. Take a moment to inspect it using the same commands you used before. You'll notice that it has the same issue of `NaN` values, but there's a new problem, too: The home prices are in Mexican pesos (`\"price_mxn\"`), not US dollars (`\"price_usd\"`). If we want to compare all the home prices in this dataset, they all need to be in the same currency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353fc6cb",
   "metadata": {},
   "source": [
    "**Task 1.2.4:** First, drop rows with `NaN` values in `df2`. Next, use the `\"price_mxn\"` column to create a new column named `\"price_usd\"`. (Keep in mind that, when this data was collected in 2014, a dollar cost 19 pesos.) Finally, drop the `\"price_mxn\"` from the DataFrame.\n",
    "\n",
    "- **Drop rows with missing values from a DataFrame using pandas.**\n",
    "- **Create new columns derived from existing columns in a DataFrame using pandas.**\n",
    "- **Drop a column from a DataFrame using pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b410ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed06d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'Nan' values\n",
    "df2.dropna(inplace=True)\n",
    "\n",
    "#Create a `\"price_usd\"` col\n",
    "df2[\"price_usd\"] = (df2[\"price_mxn\"] / 19).round(2)\n",
    "\n",
    "#Drop `\"price_mxn\"` col\n",
    "df2.drop(columns=[\"price_mxn\"], inplace=True)\n",
    "\n",
    "df2.info()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda74d5",
   "metadata": {},
   "source": [
    "## Clean `df3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bfe9ec",
   "metadata": {},
   "source": [
    "Great work! We're now on the final DataFrame. Use the same `shape`, `info` and `head` commands to inspect the `df3`. Do you see any familiar issues? \n",
    "\n",
    "You'll notice that we still have `NaN` values, but there are two new problems:\n",
    "\n",
    "1. Instead of separate `\"lat\"` and `\"lon\"` columns, there's a single `\"lat-lon\"` column. \n",
    "2. Instead of a `\"state\"` column, there's a `\"place_with_parent_names\"` column.\n",
    "\n",
    "We need the resolve these problems so that `df3` has the same columns in the same format as `df1` and `df2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc74fe",
   "metadata": {},
   "source": [
    "**Task 1.2.5:** Drop rows with `NaN` values in `df3`. Then use the [`split`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) method to create two new columns from `\"lat-lon\"` named `\"lat\"` and `\"lon\"`, respectively.\n",
    "\n",
    "- **Drop rows with missing values from a DataFrame using pandas.**\n",
    "- **Split the strings in one column to create another using pandas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape\n",
    "df3.info()\n",
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop `NaN` rows\n",
    "df3.dropna(inplace=True)\n",
    "\n",
    "# Split `\"lat-lon\"`\n",
    "df3[[\"lat\", \"lon\"]] = df3[\"lat-lon\"].str.split(\",\", expand=True)\n",
    "\n",
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2d475",
   "metadata": {},
   "source": [
    "**Task 1.2.6:** Use the [`split`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) method again, this time to extract the state for every house. (Note that the state name always appears after `\"MÃ©xico|\"` in each string.) Use this information to create a `\"state\"` column. Finally, drop the `\"place_with_parent_names\"` and `\"lat-lon\"` columns from the DataFrame. \n",
    "\n",
    "- **Split the strings in one column to create another using pandas.**\n",
    "- **Drop a column from a DataFrame using pandas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc739d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81e0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db43e7b5",
   "metadata": {},
   "source": [
    "## Concatenate DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e0a5e2",
   "metadata": {},
   "source": [
    "Great work! You have three clean DataFrames, and now it's time to combine them into a single DataFrame so that you can conduct your analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb25fd9e",
   "metadata": {},
   "source": [
    "**Task 1.2.7:** Use [`pd.concat`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) to concatenate `df1`, `df2`, `df3` as new DataFrame named `df`. Your new DataFrame should have 1,736 rows and 6 columns:`\"property_type\"`, `\"state\"`, `\"lat\"`, `\"lon\"`, `\"area_m2\"`, `\"price_usd\"`, and `\"price_per_m2\"`. \n",
    "\n",
    "- **Concatenate two or more DataFrames using pandas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9727d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ...\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b705978",
   "metadata": {},
   "source": [
    "## Save `df`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e3049d",
   "metadata": {},
   "source": [
    "The data is clean and in a single DataFrame, and now you need to save it as a CSV file so that you can examine it in your exploratory data analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f2e33",
   "metadata": {},
   "source": [
    "**Task 1.2.8:** Save `df` as a CSV file using the [`to_csv`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html) method. The file path should be `\"./data/mexico-real-estate-clean.csv\"`. Be sure to set the `index` argument to `False`.\n",
    "\n",
    "- **What's a CSV file?**\n",
    "- **Save a DataFrame as a CSV file using pandas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6707e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27a41dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
